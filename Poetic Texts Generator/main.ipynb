{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8e6b852-daa5-4642-92e0-e40d3c302426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original text: 6932\n",
      "Length of sliced text: 6932\n",
      "Number of sequences generated: 2278\n",
      "Epoch 1/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - loss: 3.8852\n",
      "Epoch 2/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 3.5111\n",
      "Epoch 3/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 3.4572\n",
      "Epoch 4/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 3.3324\n",
      "Epoch 5/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 3.1139\n",
      "Epoch 6/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 2.8403\n",
      "Epoch 7/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 2.6566\n",
      "Epoch 8/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 2.4078\n",
      "Epoch 9/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 2.1776\n",
      "Epoch 10/10\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 2.0371\n",
      "---------0.1---------\n",
      "or: #000;}#redirect-main-text {font-size:  14px ; padding-top:  24px ; width:  100% ; margin: auto; fonter: #3px ; fonter: #3xpx ; fonter:  uute; fonter: #3px ; fonter: #3px ; fonter:  utore; farderent-sizen-boxten  utepe; fonter: #3px ; fonter:  uute; fonter: #3px ; fonter: #3xpx; fanter:  uute; fonter: #orderered-seadiren-borderent-size:  2px ; fonter:  uute; fonter: #3px ; fonter: #3px ; fonter\n",
      "---------0.2---------\n",
      "ref=\"https://www.youtube.com/img/favicon_48.png\" sizes=\"48x48\"><link rel=\"icon\" href=\"https://www.youten: 000ppx ; #ext-radiut: 000;}##erdin-red-redd-redd-redd-redd-redd-redd-redd-redd-redd-sead-redd-redd-redd-redd-redd-red-redd-redd-redd-redd-redd-redd-redd-sead-redd-redd-redd-redd-redd-redd-redd-redd-redd-redd-redd-redd-sead-redd-redd-redd-redd-redd-redd-redd-redd-redd-redd-redd-redt-badiun:  2p\n",
      "---------0.3---------\n",
      "class=\"search-form\" action=\"https://www.youtube.com/results\"><script nonce=\"cneilo2bgy9tukw4tllb3w\"><din =\" tubed=\"  = pex ; fonter: #000;}##erding-sack-cont-inten-borddin:  2px ; border:  uute; farddin:  ute; fonter: #ox; ; fenter:  uute; 10; pedding-sead-redd-redd-redd-int-nt-border:  0ppx ; fonter: 000; forder-sinte   2px  =\" dererer: 000porder-redd-redd-radinen-border-sead-redd-redding:  uupe;\n",
      "---------0.4---------\n",
      "direct-warning-text {font-size:  24px ; color: #000;}#pending-url-redirect-warning-text {font-size:  0px ; forder-teat-ing-tond-sistht: utpearere; boxten  0px corgen-seaderent-seadir:  upox ; #edding-sadch-bolder=\" steader:  0pon  =\" sered-raddin:  2px ; fenten-borde=\" conter: #36x ; border:  2ux ; fontent-bolde =\"  cuten   uuten;}#ackinon_-size:  22px  =\" stearer:  uute; fontered-redd-redd-redd-r\n",
      "---------0.5---------\n",
      "=\"masthead-search-terms-border\" dir=\"ltr\"><input id=\"masthead-search-terms\" autocomplete=\"off\" name=\"  uteder; sedther: uup e = 2x = iterermatten: 000;;}#allin: 2 #=\" f fne-tead-read-raddinen {dis=\" nutestargh-text-masghe: 10px ; benter:  undder=\" stearer-bexte   uute; fent-seade;  2px ;  fonterar int-sarch-bond-size=\" site=\" conter: #opx  f x utevereradereat-sead-weadch: 002px }#onte; }#orde; y-t\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import random\n",
    "\n",
    "# Download Shakespeare text file\n",
    "filepath = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    ")\n",
    "\n",
    "# Read and preprocess text\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "# Debug: Print the length of the original text\n",
    "print(f\"Length of original text: {len(text)}\")\n",
    "\n",
    "# Use the full text or adjust slicing if needed\n",
    "text = text[:len(text)]  # You can modify this if you want to limit the text\n",
    "\n",
    "# Debug: Print the length of the sliced text\n",
    "print(f\"Length of sliced text: {len(text)}\")\n",
    "\n",
    "# Ensure the text is long enough for sequence generation\n",
    "if len(text) <= 40:\n",
    "    raise ValueError(\"Text length is too short for the specified SEQ_LENGTH. Adjust the slicing or use a smaller SEQ_LENGTH.\")\n",
    "\n",
    "# Create character-index mappings\n",
    "characters = sorted(set(text))\n",
    "char_to_index = {c: i for i, c in enumerate(characters)}\n",
    "index_to_char = {i: c for i, c in enumerate(characters)}\n",
    "\n",
    "# Parameters for sequence generation\n",
    "SEQ_LENGTH = 100\n",
    "STEP_SIZE = 3\n",
    "\n",
    "# Prepare input sequences and their corresponding target characters\n",
    "sentences = []\n",
    "next_characters = []\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_characters.append(text[i + SEQ_LENGTH])\n",
    "\n",
    "# Debug: Check the number of sequences generated\n",
    "print(f\"Number of sequences generated: {len(sentences)}\")\n",
    "\n",
    "# Ensure that there are sequences generated\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No training sequences were generated. Check SEQ_LENGTH and text length.\")\n",
    "\n",
    "# Create one-hot encoded data arrays\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1\n",
    "    y[i, char_to_index[next_characters[i]]] = 1\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, batch_size=256, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "model.save('textgenerator.keras')\n",
    "\n",
    "# Load the model for inference\n",
    "model = tf.keras.models.load_model('textgenerator.keras')\n",
    "\n",
    "# Function to sample from the predictions with temperature control\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)  # Corrected line\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, character in enumerate(sentence):\n",
    "            x[0, t, char_to_index[character]] = 1\n",
    "\n",
    "        predictions = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)  # Corrected 'temprature' to 'temperature'\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated\n",
    "\n",
    "# Example usage with different temperatures\n",
    "print('---------0.1---------')\n",
    "print(generate_text(300, 0.1))\n",
    "print('---------0.2---------')\n",
    "print(generate_text(300, 0.2))\n",
    "print('---------0.3---------')\n",
    "print(generate_text(300, 0.3))\n",
    "print('---------0.4---------')\n",
    "print(generate_text(300, 0.4))\n",
    "print('---------0.5---------')\n",
    "print(generate_text(300, 0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "550ebaeb-7a8e-4715-9b39-81ea26216bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original text: 6932\n",
      "Total unique characters: 59\n",
      "Number of sequences generated: 2278\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">96,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,611</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m96,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                  │           \u001b[38;5;34m7,611\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_10 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,867</span> (405.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m103,867\u001b[0m (405.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,867</span> (405.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,867\u001b[0m (405.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 3.8892\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 3.5488\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 3.4613\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 3.3797\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 3.2097\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 2.9806\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 2.6780\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 2.4609\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 2.2577\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 2.0435\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 1.8452\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 1.6468\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 1.5065\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 1.3330\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 1.1485\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 1.0307\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.8389\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.6663\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.6261\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.4915\n",
      "\n",
      "--- Generating with temperature 0.2 ---\n",
      "Seed: padding:  12px ; text-transform: uppercase;; font-size: ; border-radius: 2px; font-weight: 500;}#red\n",
      "padding:  12px ; text-transform: uppercase;; font-size: ; border-radius: 2px; font-weight: 500;}#redirect-barch-sitt-backiro().ddde==\"teltwearch-tent-search-tont-search-torms''..steareitelts: bocktrodddins:  uuton { border-lox; fant-size:  22px ; bolder: #888;calsit: f6nte;}#ederadding-tot-button {{forler-boxt-wearch-tent-search-terms'alocutent.sfardid-seath:  u2px ; bockhr: #000; margin:000;poled\n",
      "\n",
      "--- Generating with temperature 0.5 ---\n",
      "Seed: function(e) {if (document.getelementbyid('masthead-search-terms').value == '') {e.preventdefault();}\n",
      "function(e) {if (document.getelementbyid('masthead-search-terms').value == '') {e.preventdefault();});});</script><ddis =\"ytt-s:00; herght:15px;haight:0%px;margin-tol:154px; outlis=\"yton\" inpt\"><d-size /tocon: 44px at-wetint-lock-redirect-tott-search-tont-search-terms'antite = mardine = 3uton\" yiten\" colten {boxder: ionte; boxthr: #e0pe; boxt-redirect-bordin-lize:  22px ; boler:10; ledd-redirect-c\n",
      "\n",
      "--- Generating with temperature 1.0 ---\n",
      "Seed: .youtube.com/results\"><script nonce=\"cneilo2bgy9tukw4tllb3w\">document.addeventlistener('domcontentlo\n",
      ".youtube.com/results\"><script nonce=\"cneilo2bgy9tukw4tllb3w\">document.addeventlistener('domcontentloade.grsidt-ueto-butto<\" 34px th:aote;}#edder:1 2ddeverghte-stereay-redt-radiun:  3upo t: #elt-toltis:cof8; inder: 0 0unl-sea1 head-wedtre6t-bor: i0px a  32zx 24x thesermargin-ton ener\"></der=</sirg/it-toft:/wp.gstead-search-terms''.cldei adiaker: 25px ; boxte;: hedd-radifn: conte;}#xeleredemarlint-t\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import random\n",
    "\n",
    "# Download Shakespeare text file\n",
    "filepath = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    ")\n",
    "\n",
    "# Read and preprocess text\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "print(f\"Length of original text: {len(text)}\")\n",
    "\n",
    "# Parameters for sequence generation\n",
    "SEQ_LENGTH = 100\n",
    "STEP_SIZE = 3\n",
    "\n",
    "# Ensure the text is long enough for sequence generation\n",
    "if len(text) <= SEQ_LENGTH:\n",
    "    raise ValueError(\"Text length is too short for the specified SEQ_LENGTH.\")\n",
    "\n",
    "# Create character-to-index and index-to-character mappings\n",
    "characters = sorted(set(text))\n",
    "char_to_index = {c: i for i, c in enumerate(characters)}\n",
    "index_to_char = {i: c for i, c in enumerate(characters)}\n",
    "print(f\"Total unique characters: {len(characters)}\")\n",
    "\n",
    "# Prepare input sequences and their corresponding target characters\n",
    "sentences = []\n",
    "next_characters = []\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_characters.append(text[i + SEQ_LENGTH])\n",
    "\n",
    "print(f\"Number of sequences generated: {len(sentences)}\")\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No training sequences were generated. Check SEQ_LENGTH and text length.\")\n",
    "\n",
    "# One-hot encode input (x) and target (y) data\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.float32)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=np.float32)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1\n",
    "    y[i, char_to_index[next_characters[i]]] = 1\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(SEQ_LENGTH, len(characters))),\n",
    "    Dense(len(characters)),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, batch_size=256, epochs=20)\n",
    "\n",
    "# Save the model\n",
    "model.save('textgenerator.keras')\n",
    "\n",
    "# Load the model for inference\n",
    "model = tf.keras.models.load_model('textgenerator.keras')\n",
    "\n",
    "# Function to sample from the predictions with temperature control\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-7) / temperature  # Add small value to avoid log(0)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated = sentence\n",
    "    print(f\"Seed: {sentence}\")\n",
    "\n",
    "    for _ in range(length):\n",
    "        x_pred = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated\n",
    "\n",
    "# Generate text with varying temperatures\n",
    "for temp in [0.2, 0.5, 1.0]:\n",
    "    print(f\"\\n--- Generating with temperature {temp} ---\")\n",
    "    print(generate_text(300, temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe41a7-a6fd-4b94-8b18-bbf1195cca8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
